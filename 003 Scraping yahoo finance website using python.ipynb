{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gspread\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "from pprint import pprint\n",
    "import yfinance as yf\n",
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gathering the Google Sheets API credentials locally and connecting them to the sheets to access data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scope = [\"https://spreadsheets.google.com/feeds\",'https://www.googleapis.com/auth/spreadsheets',\"https://www.googleapis.com/auth/drive.file\",\"https://www.googleapis.com/auth/drive\"]\n",
    "# Replace XXXX with the path to the google sheets api credentials (creds.json file that is saved locally)\n",
    "path = r\"XXXXX\"\n",
    "creds = ServiceAccountCredentials.from_json_keyfile_name(path + \"creds.json\",  scope, token_uri = \"https://oauth2.googleapis.com/token\")\n",
    "client = gspread.authorize(creds)\n",
    "sheet = client.open(r'XXXXX') # Replace XXXX with the google sheet name\n",
    "sheet1 = sheet.worksheet(\"Company Financial analysis\")\n",
    "maxlen = 150  # Max number of records\n",
    "\n",
    "def profiledata(ticker, page, attr, position):\n",
    "    # This function takes \n",
    "    #       - ticker (eg: AAPL)\n",
    "    #       - page (eg: financials or balance-sheet or key-statistics)\n",
    "    #       - attr (eg: Net Income, Revenue etc from each of the pages. Works with most but not all attributes)\n",
    "    #       - position (eg: 1, 2, 3 etc. What is the column number where the data is located)\n",
    "    try:\n",
    "        # Obtaining the source url based on the ticker, page etc.\n",
    "        source = str('https://ca.finance.yahoo.com/quote/') + ticker + str('/') + page + str(r'?p=') + ticker\n",
    "        # Accessing the url using the requests module\n",
    "        r = requests.get(source)\n",
    "        # Converting and accessing the url as an lxml using beautiful soup\n",
    "        soup = bs4.BeautifulSoup(r.text,'lxml')\n",
    "        # Try to find the div type in the lxml called rw-expanded if it exists\n",
    "        rows = soup.find_all('div', {'class':'rw-expnded'})\n",
    "        struct = 'div'\n",
    "        # If data is tabular, it will be tr instead of div\n",
    "        if len(rows)==0:\n",
    "            rows = soup.find_all('tr')\n",
    "            struct = 'tr'\n",
    "        value = '-'\n",
    "        # Looping through each div or tr section in the lxml and matching first text to the attr\n",
    "        for i in rows:\n",
    "            if i.find_all('span')[0].text == attr:\n",
    "                if struct == 'div':\n",
    "                    value = i.find_all('span')[position].text\n",
    "                    break\n",
    "                elif struct == 'tr':\n",
    "                    value = i.find_all('td')[position].text\n",
    "                    break\n",
    "            else:\n",
    "                value = \"-\"\n",
    "    except:\n",
    "        value = '-'\n",
    "    return value\n",
    "\n",
    "\n",
    "for i in range(123,maxlen):\n",
    "    t = sheet1.cell(i+3,5).value  # Get the ticker from the 5th column\n",
    "    if not len(t)==0:\n",
    "        \n",
    "        # Calling the profiledata function for all the following parameters\n",
    "        rev2019 = profiledata(t, 'financials', 'Total Revenue', 2 )\n",
    "        rev2018 = profiledata(t, 'financials', 'Total Revenue', 3 )\n",
    "        rev2017 = profiledata(t, 'financials', 'Total Revenue', 4 )\n",
    "        ebitda2019 = profiledata(t, 'financials', 'EBITDA', 1)\n",
    "        ebitda2018 = profiledata(t, 'financials', 'EBITDA', 2)\n",
    "        ebitda2017 = profiledata(t, 'financials', 'EBITDA', 3)\n",
    "        netincome = profiledata(t, 'financials', 'Net Income', 2)\n",
    "        interestexp = profiledata(t, 'financials', 'Interest Expense', 2)\n",
    "        totliabilities = profiledata(t, 'balance-sheet', 'Total Liabilities', 1)\n",
    "        totequities = profiledata(t, 'balance-sheet', \"Total stockholders' equity\", 1)\n",
    "        p_e = profiledata(t, 'key-statistics', 'Trailing P/E', 1)\n",
    "\n",
    "        # Updating various columns in the google sheet with the stock parameters obtained\n",
    "        sheet1.update_cell(i+3,6,rev2019)\n",
    "        sheet1.update_cell(i+3,7,rev2018)\n",
    "        sheet1.update_cell(i+3,8,rev2017)\n",
    "        sheet1.update_cell(i+3,9,ebitda2019)\n",
    "        sheet1.update_cell(i+3,10,ebitda2018)\n",
    "        sheet1.update_cell(i+3,11,ebitda2017)\n",
    "        sheet1.update_cell(i+3,12,totliabilities)\n",
    "        sheet1.update_cell(i+3,13,totequities)\n",
    "        sheet1.update_cell(i+3,14,p_e)\n",
    "        sheet1.update_cell(i+3,15,netincome)\n",
    "        sheet1.update_cell(i+3,16,interestexp)\n",
    "        \n",
    "        # Sleeping after quering all the above to avoid crossing the google api read/write limits\n",
    "        time.sleep(15)\n",
    "    else:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
